# _tools/analyze_data_coverage.py
import argparse
import pandas as pd
from pathlib import Path
from tqdm import tqdm
import warnings
import matplotlib.pyplot as plt

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø—É—Ç–∏ –∏ –∑–∞–≥—Ä—É–∑—á–∏–∫ –∏–∑ –≤–∞—à–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
from _core.paths import DATA_DIR, RESULTS_DIR, ensure_dirs
from _core.data_loader import load_data

# –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º, —á—Ç–æ –≤—Å–µ –ø–∞–ø–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
ensure_dirs()
warnings.simplefilter('ignore', FutureWarning)

def get_date_range_for_ticker(ticker: str) -> dict | None:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –æ–¥–Ω–æ–≥–æ —Ç–∏–∫–µ—Ä–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω.
    """
    df = load_data(ticker)
    
    if df is None or df.empty or 'datetime' not in df.columns:
        return {
            "ticker": ticker,
            "start_date": "N/A",
            "end_date": "N/A",
            "total_days": 0,
            "error": "File not found or empty"
        }
        
    try:
        start_date = df['datetime'].min().date()
        end_date = df['datetime'].max().date()
        total_days = len(df)
        
        return {
            "ticker": ticker,
            "start_date": start_date,
            "end_date": end_date,
            "total_days": total_days,
            "error": None
        }
    except Exception as e:
        return {
            "ticker": ticker,
            "start_date": "N/A",
            "end_date": "N/A",
            "total_days": 0,
            "error": str(e)
        }

def main(args):
    print("--- üî¨ –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è —Å–∫–∞—á–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö ---")

    # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ç–∏–∫–µ—Ä–æ–≤
    universe_path = Path(args.universe_file)
    if not universe_path.exists():
        print(f"‚ùå –§–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º –∞–∫—Ü–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω: {universe_path}"); return
        
    try:
        tickers = pd.read_csv(universe_path)['ticker'].tolist()
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(tickers)} —Ç–∏–∫–µ—Ä–æ–≤ –≤ —Ñ–∞–π–ª–µ {args.universe_file}")
    except Exception as e:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª {universe_path}: {e}"); return

    # 2. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ç–∏–∫–µ—Ä
    all_reports = []
    for ticker in tqdm(tickers, desc="–ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–æ–≤"):
        report = get_date_range_for_ticker(ticker)
        if report:
            all_reports.append(report)
            
    if not all_reports:
        print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞."); return

    # 3. –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
    report_df = pd.DataFrame(all_reports)
    report_df = report_df[report_df['total_days'] > 0] # –ò—Å–∫–ª—é—á–∞–µ–º —Ç–∏–∫–µ—Ä—ã –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö
    report_df.sort_values(by="start_date", ascending=False, inplace=True)
    
    report_dir = RESULTS_DIR / "reports"
    report_dir.mkdir(exist_ok=True)
    
    output_path_csv = report_dir / "data_coverage_report.csv"
    report_df.to_csv(output_path_csv, index=False)
    
    # --- üëá –ù–û–í–´–ô –ë–õ–û–ö: –ü–û–°–¢–†–û–ï–ù–ò–ï –ì–ò–°–¢–û–ì–†–ê–ú–ú–´ üëá ---
    print("\n–°–æ–∑–¥–∞–Ω–∏–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è...")
    plt.figure(figsize=(14, 7))
    
    plt.hist(report_df['total_days'], bins=50, color='skyblue', edgecolor='black', alpha=0.8)
    
    plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ –∞–∫—Ü–∏—è–º', fontsize=16)
    plt.xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π –≤ –∏—Å—Ç–æ—Ä–∏–∏')
    plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ü–∏–π')
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ –ª–∏–Ω–∏–∏ –¥–ª—è —Å—Ä–µ–¥–Ω–µ–≥–æ –∏ –º–µ–¥–∏–∞–Ω—ã
    mean_days = report_df['total_days'].mean()
    median_days = report_df['total_days'].median()
    plt.axvline(mean_days, color='red', linestyle='dashed', linewidth=2, label=f'–°—Ä–µ–¥–Ω–µ–µ: {mean_days:.0f} –¥–Ω–µ–π')
    plt.axvline(median_days, color='green', linestyle='dashed', linewidth=2, label=f'–ú–µ–¥–∏–∞–Ω–∞: {median_days:.0f} –¥–Ω–µ–π')
    
    plt.legend()
    plt.yscale('log') # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∞—è —à–∫–∞–ª–∞ –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
    plt.gca().get_yaxis().set_major_formatter(plt.ScalarFormatter()) # –û—Ç–∫–ª—é—á–∞–µ–º –Ω–∞—É—á–Ω—É—é –Ω–æ—Ç–∞—Ü–∏—é –Ω–∞ –æ—Å–∏ Y
    
    output_path_png = report_dir / "data_coverage_histogram.png"
    plt.savefig(output_path_png)
    print(f"‚úÖ –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {output_path_png}")
    # ---------------------------------------------------

    print("\n" + "="*50)
    print("--- üìä –ò—Ç–æ–≥–∏ –∞–Ω–∞–ª–∏–∑–∞ ---")
    
    print(f"\n–ü–æ–ª–Ω—ã–π CSV –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {output_path_csv}")
    print("="*50)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ –∞–∫—Ü–∏—è–º –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã.")
    parser.add_argument(
        '--universe_file',
        type=str,
        default='universe.csv',
        help='–§–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º —Ç–∏–∫–µ—Ä–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.'
    )
    args = parser.parse_args()
    main(args)