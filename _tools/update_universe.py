# _tools/update_universe.py
import argparse
import pandas as pd
from functools import partial
import time
import json
import os
import requests

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ –∏–∑ –≤–∞—à–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
from _core.paths import ensure_dirs, RESULTS_DIR
from _core.libs import tqdm, multiprocessing

ensure_dirs()

# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã, —á—Ç–æ–±—ã —Å–∫—Ä–∏–ø—Ç –±—ã–ª —Å–∞–º–æ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º ---
MOEX_BASE = "https://iss.moex.com/iss/history/engines/stock/markets/shares/boards/{board}/securities"
DEFAULT_BOARD = "TQBR"

def _make_session() -> requests.Session:
    """–°–æ–∑–¥–∞–µ—Ç —Å–µ—Å—Å–∏—é –¥–ª—è HTTP-–∑–∞–ø—Ä–æ—Å–æ–≤."""
    s = requests.Session()
    s.headers.update({"User-Agent": "trader_test/1.0"})
    return s

def get_initial_moex_tickers():
    """
    –ü–æ–ª—É—á–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ç–æ—Ä–≥—É–µ–º—ã—Ö –∞–∫—Ü–∏–π —Å –ú–æ—Å–±–∏—Ä–∂–∏.
    """
    print("–ó–∞–ø—Ä–∞—à–∏–≤–∞—é –∞–∫—Ç—É–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∞–∫—Ü–∏–π —Å –ú–æ—Å–∫–æ–≤—Å–∫–æ–π –±–∏—Ä–∂–∏...")
    base_url = "https://iss.moex.com/iss/engines/stock/markets/shares/boards/TQBR/securities.json"
    params = {"iss.meta": "off", "iss.only": "securities,securities.cursor", 'iss.json': 'extended'}
    all_tickers = []
    start = 0
    
    with _make_session() as session:
        while True:
            try:
                current_params = params.copy()
                current_params['securities.cursor'] = start
                
                response = session.get(base_url, params=current_params, timeout=20)
                response.raise_for_status()
                
                data = response.json()

                if not isinstance(data, list) or len(data) < 2:
                    break
                
                data_block = data[1]
                
                securities_list = data_block.get('securities')
                if securities_list and isinstance(securities_list, list):
                    for row in securities_list:
                        if isinstance(row, dict) and 'SECID' in row:
                            all_tickers.append(str(row['SECID']))
                else:
                    break
                
                cursor_list = data_block.get('securities.cursor')
                if cursor_list and isinstance(cursor_list, list) and cursor_list:
                    cursor_data = cursor_list[0]
                    if isinstance(cursor_data, dict):
                        total = cursor_data.get('TOTAL', 0)
                        page_size = cursor_data.get('PAGESIZE', 100)
                        start += page_size
                        
                        if start >= total:
                            break
                    else:
                        break
                else:
                    break
                
                time.sleep(0.25)
                
            except requests.RequestException as e:
                print(f"‚ö†Ô∏è  –°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –∞–∫—Ü–∏–π: {e}. –ü—Ä–µ—Ä—ã–≤–∞—é.")
                return []
            except Exception as e:
                print(f"‚ö†Ô∏è  –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞: {e}. –ü—Ä–µ—Ä—ã–≤–∞—é.")
                return []

    unique_tickers = sorted(list(set(all_tickers)))
    print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(unique_tickers)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–∏–∫–µ—Ä–æ–≤.")
    return unique_tickers


def get_history_days_count(ticker: str, session: requests.Session) -> dict:
    """
    –î–ª—è –æ–¥–Ω–æ–≥–æ —Ç–∏–∫–µ—Ä–∞ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π.
    """
    url = MOEX_BASE.format(board=DEFAULT_BOARD) + f"/{ticker}.json"
    params = {'limit': 1, 'iss.json': 'extended', 'iss.meta': 'off'}
    
    try:
        response = session.get(url, params=params, timeout=15)
        if response.status_code != 200:
            return {"ticker": ticker, "history_days": 0, "error": f"HTTP status {response.status_code}"}
            
        data = response.json()
        
        if isinstance(data, list) and len(data) > 1:
            history_cursor_block = data[1].get('history.cursor')
            if history_cursor_block and isinstance(history_cursor_block, list) and history_cursor_block:
                try:
                    total_days = history_cursor_block[0].get('TOTAL', 0)
                    return {"ticker": ticker, "history_days": int(total_days), "error": None}
                except (ValueError, IndexError):
                    return {"ticker": ticker, "history_days": 0, "error": "Could not parse 'TOTAL' from data"}
        
        return {"ticker": ticker, "history_days": 0, "error": "Unexpected JSON structure"}
    
    except requests.exceptions.RequestException as e:
        return {"ticker": ticker, "history_days": 0, "error": f"Network error: {type(e).__name__}"}
    except json.JSONDecodeError:
        return {"ticker": ticker, "history_days": 0, "error": "Invalid JSON response"}
    except Exception as e:
        return {"ticker": ticker, "history_days": 0, "error": f"Unexpected error: {e}"}


def main(args):
    """–û—Å–Ω–æ–≤–Ω–æ–π –ø–∞–π–ø–ª–∞–π–Ω: –ø–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞, –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ."""
    
    initial_tickers = get_initial_moex_tickers()
    if not initial_tickers:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∞–∫—Ü–∏–π. –ó–∞–≤–µ—Ä—à–∞—é —Ä–∞–±–æ—Ç—É.")
        return

    print(f"\n--- üïµÔ∏è –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è {len(initial_tickers)} —Ç–∏–∫–µ—Ä–æ–≤ ---")
    
    with _make_session() as session:
        worker_func = partial(get_history_days_count, session=session)
        
        with multiprocessing.Pool(processes=args.workers) as pool:
            results = list(tqdm(pool.imap(worker_func, initial_tickers), total=len(initial_tickers), desc="–ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—Ä–∏–∏"))

    report_df = pd.DataFrame(results)
    
    # --- –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –°–Ω–∞—á–∞–ª–∞ –æ—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ, –ø–æ—Ç–æ–º —Å–æ—Ä—Ç–∏—Ä—É–µ–º –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º ---
    # 1. –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —á–∏—Å–ª–∞, –≤—Å–µ –æ—à–∏–±–∫–∏ (–Ω–µ—á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è) —Å—Ç–∞–Ω—É—Ç NaN
    report_df['history_days'] = pd.to_numeric(report_df['history_days'], errors='coerce')
    # 2. –ó–∞–ø–æ–ª–Ω—è–µ–º –≤—Å–µ NaN (–≤–∫–ª—é—á–∞—è —Ç–µ, —á—Ç–æ –ø–æ—è–≤–∏–ª–∏—Å—å –ø–æ—Å–ª–µ to_numeric) –Ω—É–ª—è–º–∏ –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ —Ü–µ–ª–æ–º—É —á–∏—Å–ª—É
    report_df['history_days'] = report_df['history_days'].fillna(0).astype(int)
    
    # 3. –¢–µ–ø–µ—Ä—å, –∫–æ–≥–¥–∞ –∫–æ–ª–æ–Ω–∫–∞ —á–∏—Å—Ç–∞—è, —Å–æ—Ä—Ç–∏—Ä—É–µ–º
    report_df.sort_values('history_days', ascending=False, inplace=True)
    
    report_path = RESULTS_DIR / "universe_full_report.csv"
    report_df.to_csv(report_path, index=False)
    print(f"\nüìä –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –æ –¥–ª–∏–Ω–µ –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {report_path}")
    
    errors_df = report_df[report_df['error'].notna()]
    if not errors_df.empty:
        print("\n--- ‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ç–∏–∫–µ—Ä–æ–≤ ---")
        error_counts = errors_df['error'].value_counts()
        print(error_counts.to_string())
        print("----------------------------------------------------")

    # 4. –¢–µ–ø–µ—Ä—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
    filtered_df = report_df[report_df['history_days'] >= args.min_days]
    filtered_tickers = filtered_df['ticker'].tolist()

    print("\n" + "="*50)
    print("--- üî¨ –ò—Ç–æ–≥–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ ---")
    print(f"–í—Å–µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {len(report_df)} —Ç–∏–∫–µ—Ä–æ–≤")
    print(f"–ü—Ä–æ—à–ª–∏ —Ñ–∏–ª—å—Ç—Ä (–∏—Å—Ç–æ—Ä–∏—è >= {args.min_days} –¥–Ω–µ–π): {len(filtered_tickers)} —Ç–∏–∫–µ—Ä–æ–≤")
    print(f"–û—Ç–±—Ä–æ—à–µ–Ω–æ: {len(report_df) - len(filtered_tickers)} —Ç–∏–∫–µ—Ä–æ–≤")
    print("="*50)
    
    if filtered_tickers:
        universe_df = pd.DataFrame(filtered_tickers, columns=['ticker'])
        universe_df.to_csv(args.output_file, index=False)
        print(f"\n‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π `universe.csv` —Å–æ—Ö—Ä–∞–Ω–µ–Ω.")
    else:
        print(f"\n‚ö†Ô∏è –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ç–∏–∫–µ—Ä–∞. –§–∞–π–ª `{args.output_file}` –Ω–µ –±—ã–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–ø–∏—Å–∫–∞ –∞–∫—Ü–∏–π MOEX –ø–æ –¥–ª–∏–Ω–µ –∏—Å—Ç–æ—Ä–∏–∏.")
    parser.add_argument('--min-days', type=int, default=252, help="–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π –≤ –∏—Å—Ç–æ—Ä–∏–∏.")
    parser.add_argument('--output-file', type=str, default='universe.csv', help="–ò–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å–æ —Å–ø–∏—Å–∫–æ–º —Ç–∏–∫–µ—Ä–æ–≤.")
    parser.add_argument('--workers', type=int, default=os.cpu_count(), help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤.")
    
    args = parser.parse_args()
    main(args)