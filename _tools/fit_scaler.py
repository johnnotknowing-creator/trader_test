# _tools/fit_scaler.py
# -*- coding: utf-8 -*-
"""
–û–±—É—á–µ–Ω–∏–µ Pipeline (Imputer + RobustScaler) –Ω–∞ train-–¥–∞–Ω–Ω—ã—Ö –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ¬´–±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ¬ª —Å–∫–µ–π–ª–µ—Ä–∞.
–ó–∞–ø—É—Å–∫:
    python -m _tools.fit_scaler --model_name EXP1
–û–ø—Ü–∏–∏:
    --train_path      (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ) –ø—É—Ç—å –∫ train_final.csv; –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –±–µ—Ä—ë—Ç—Å—è –∏–∑ final_for_model/<model_name>/
    --label_col       –∏–º—è –∫–æ–ª–æ–Ω–∫–∏ —Å –º–µ—Ç–∫–æ–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: label)
"""

from __future__ import annotations

import os
import sys
import json
import argparse
import warnings
from pathlib import Path
from typing import List, Tuple

import numpy as np
import pandas as pd

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import RobustScaler
from sklearn.pipeline import Pipeline
import joblib

# --- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—É—Ç–µ–π –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤ –ø–∞–∫–µ—Ç–∞ ---
ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))

from _core.paths import RESULTS_DIR, ensure_dirs  # PROJECT_ROOT –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –∑–¥–µ—Å—å

warnings.simplefilter("ignore", UserWarning)


def _resolve_paths(model_name: str, train_path: str | None) -> Tuple[Path, Path, Path, Path]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (train_csv, scalers_dir, scaler_pkl_target)
    """
    base = RESULTS_DIR / "final_for_model" / model_name
    if train_path:
        train_csv = Path(train_path)
    else:
        train_csv = base / "train_final.csv"
    scalers_dir = RESULTS_DIR / "scalers"
    scaler_pkl = scalers_dir / f"{model_name}_scaler.pkl"
    features_json = scalers_dir / f"{model_name}_features.json"
    return train_csv, scalers_dir, scaler_pkl, features_json


def _detect_feature_columns(df: pd.DataFrame, label_col: str) -> List[str]:
    bad_cols = {"datetime", "ticker", label_col}
    # –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ–≤—ã–µ –∏ –ù–ï —Å–ª—É–∂–µ–±–Ω—ã–µ
    num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
    feat_cols = [c for c in num_cols if c not in bad_cols]
    return feat_cols


def _quick_sanity_check(X: np.ndarray) -> Tuple[int, int]:
    n_nan = int(np.isnan(X).sum())
    n_inf = int(np.isinf(X).sum())
    return n_nan, n_inf


def main(args: argparse.Namespace) -> None:
    ensure_dirs()

    train_csv, scalers_dir, scaler_pkl, features_json = _resolve_paths(args.model_name, args.train_path)

    if not train_csv.exists():
        raise FileNotFoundError(f"–ù–µ –Ω–∞–π–¥–µ–Ω train csv: {train_csv}")

    print("‚Äî" * 60)
    print("üß∞ –û–±—É—á–µ–Ω–∏–µ —Å–∫–µ–π–ª–µ—Ä–∞ (Imputer + RobustScaler)")
    print(f"–ú–æ–¥–µ–ª—å: {args.model_name}")
    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑: {train_csv}")
    print("‚Äî" * 60)

    df = pd.read_csv(train_csv)
    if df.empty:
        raise ValueError("–§–∞–π–ª train –ø—É—Å—Ç–æ–π.")

    label_col = args.label_col
    if label_col not in df.columns:
        # –Ω–µ –ø–∞–¥–∞–µ–º –∂—ë—Å—Ç–∫–æ ‚Äî –±—ã–≤–∞–µ—Ç, —á—Ç–æ –º–µ—Ç–∫–∞ –∫–∞–∫-—Ç–æ –∏–Ω–∞—á–µ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è –≤ —ç—Ç–æ–º —ç—Ç–∞–ø–µ
        warnings.warn(f"–ö–æ–ª–æ–Ω–∫–∞ —Å –º–µ—Ç–∫–æ–π '{label_col}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ train. –ü—Ä–æ–¥–æ–ª–∂–∞—é –±–µ–∑ –Ω–µ—ë.")

    feat_cols = _detect_feature_columns(df, label_col=label_col)
    if not feat_cols:
        raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω—ã —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å–∫–µ–π–ª–µ—Ä–∞.")

    X_df = df[feat_cols]
    print(f"–ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(feat_cols)}, –æ–±—É—á–∞—é—â–∏—Ö —Å—ç–º–ø–ª–æ–≤: {X_df.shape[0]}")

    pipeline = Pipeline(steps=[
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", RobustScaler(with_centering=True, with_scaling=True, quantile_range=(5.0, 95.0)))
    ])

    print("–û–±—É—á–µ–Ω–∏–µ Pipeline (Imputer + RobustScaler)...")
    pipeline.fit(X_df)
    print("‚úÖ Pipeline —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω.")

    # --- üëá –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º X_df –¥–ª—è sanity-–ø—Ä–æ–≤–µ—Ä–∫–∏ üëá ---
    Xt = pipeline.transform(X_df.head(5000))
    n_nan, n_inf = _quick_sanity_check(Xt)
    if n_nan or n_inf:
        warnings.warn(f"–ü–æ—Å–ª–µ transform –Ω–∞–π–¥–µ–Ω—ã NaN/Inf: NaN={n_nan}, Inf={n_inf}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º ¬´–±–µ–∑–æ–ø–∞—Å–Ω—ã–π¬ª Pipeline –∏ —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    scalers_dir.mkdir(parents=True, exist_ok=True)
    joblib.dump(pipeline, scaler_pkl)
    with open(features_json, "w", encoding="utf-8") as f:
        json.dump({"feature_order": feat_cols}, f, ensure_ascii=False, indent=2)

    print(f"‚úÖ –ê–±—Å–æ–ª—é—Ç–Ω–æ '–±–µ–∑–æ–ø–∞—Å–Ω—ã–π' Pipeline —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {scaler_pkl}")
    print(f"üóÇ  –ü–æ—Ä—è–¥–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {features_json}")
    print("–ì–æ—Ç–æ–≤–æ.")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–û–±—É—á–µ–Ω–∏–µ —Å–∫–µ–π–ª–µ—Ä–∞ –ø–æ train_final.csv")
    parser.add_argument("--model_name", type=str, required=True, help="–ò–º—è –º–æ–¥–µ–ª–∏/—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ (–ø–∞–ø–∫–∞ –≤ final_for_model)")
    parser.add_argument("--train_path", type=str, default=None, help="–Ø–≤–Ω—ã–π –ø—É—Ç—å –∫ train_final.csv (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å)")
    parser.add_argument("--label_col", type=str, default="label", help="–ò–º—è —Å—Ç–æ–ª–±—Ü–∞ –º–µ—Ç–∫–∏")
    main(parser.parse_args())