# _tools/backtester.py
import argparse
import json
import joblib
from pathlib import Path
import warnings
import os

import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import matplotlib.style as style
from tqdm import tqdm

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏ –ø—É—Ç–µ–π ---
warnings.filterwarnings("ignore", category=UserWarning)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
style.use('dark_background')

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –≤–∞—à–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
try:
    from _core.paths import (
        PROJECT_DIR, RESULTS_DIR, MODELS_DIR, SCALERS_DIR, 
        FEATURES_DIR_PROCESSED as FEATURES_DIR
    )
except ImportError:
    PROJECT_DIR = Path(__file__).resolve().parent.parent
    RESULTS_DIR = PROJECT_DIR / "2_results"
    MODELS_DIR = RESULTS_DIR / "models"
    SCALERS_DIR = RESULTS_DIR / "scalers"
    FEATURES_DIR = RESULTS_DIR / "features_processed"

def create_sequences(data: np.ndarray, lookback: int):
    """–°–æ–∑–¥–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (—Å—ç–º–ø–ª—ã) –¥–ª—è LSTM/GRU."""
    X = []
    for i in range(len(data) - lookback + 1):
        X.append(data[i:i+lookback])
    return np.array(X)

def main(args):
    print(f"--- üìà –ó–∞–ø—É—Å–∫ –±–µ–∫—Ç–µ—Å—Ç–∞ –¥–ª—è –º–æ–¥–µ–ª–∏ '{args.model_name}' –Ω–∞ —Ç–∏–∫–µ—Ä–µ '{args.ticker}' ---")

    # --- 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ ---
    model_path = MODELS_DIR / args.model_name / "model.keras"
    scaler_path = SCALERS_DIR / f"{args.model_name}_scaler.pkl"
    features_path = SCALERS_DIR / f"{args.model_name}_features.json"
    metadata_path = RESULTS_DIR / f"tfrecord_{args.model_name}" / "metadata.json"

    try:
        print("–ó–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤...")
        model = tf.keras.models.load_model(model_path)
        scaler = joblib.load(scaler_path)
        with open(features_path, 'r') as f:
            feature_cols = json.load(f)['feature_order']
        with open(metadata_path, 'r') as f:
            lookback = json.load(f)['lookback']
        print(f"‚úÖ –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã. Lookback: {lookback}, –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(feature_cols)}")
    except FileNotFoundError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω –æ–¥–∏–Ω –∏–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤. {e}")
        return

    # --- 2. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---
    data_file = FEATURES_DIR / f"{args.ticker}.csv"
    if not data_file.exists():
        print(f"‚ùå –û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –¥–ª—è —Ç–∏–∫–µ—Ä–∞: {data_file}")
        return

    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–∏–∫–µ—Ä–∞ –∏–∑ {data_file}...")
    df = pd.read_csv(data_file)
    df['datetime'] = pd.to_datetime(df['datetime'])
    
    end_date = df['datetime'].max()
    start_date = end_date - pd.DateOffset(years=args.years)
    df_backtest = df[df['datetime'] >= start_date].copy()
    
    if len(df_backtest) < lookback:
        print(f"‚ùå –û—à–∏–±–∫–∞: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –±–µ–∫—Ç–µ—Å—Ç–∞ ({len(df_backtest)} —Å—Ç—Ä–æ–∫), —Ç—Ä–µ–±—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º {lookback}.")
        return

    print(f"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ {len(df_backtest)} —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–æ–¥–µ–ª–∏...")
    X_raw = df_backtest[feature_cols].values
    X_scaled = scaler.transform(X_raw)
    X_sequences = create_sequences(X_scaled, lookback)

    # --- 3. –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π ---
    print("–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏...")
    predictions_proba = model.predict(X_sequences, verbose=0)
    predictions = np.argmax(predictions_proba, axis=1)
    
    prediction_dates = df_backtest['datetime'].iloc[lookback-1:].reset_index(drop=True)
    df_signals = pd.DataFrame({'datetime': prediction_dates, 'signal': predictions})
    df_backtest = pd.merge(df_backtest, df_signals, on='datetime', how='left')

    # --- 4. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê) ---
    print("–°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞...")

    # --- üëáüëáüëá –ù–û–í–û–ï –†–ï–®–ï–ù–ò–ï üëáüëáüëá ---
    # 1. –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –∫–æ–ª–æ–Ω–∫–∏ 'close' –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏.
    df_backtest['plot_close'] = df_backtest['close']
    # 2. –ù–∞—Ö–æ–¥–∏–º –Ω–µ—Ç–æ—Ä–≥–æ–≤—ã–µ –¥–Ω–∏ (–≥–¥–µ –æ–±—ä–µ–º —Ä–∞–≤–µ–Ω 0 –∏–ª–∏ NaN) –∏ —Å—Ç–∞–≤–∏–º –≤ `plot_close` –∑–Ω–∞—á–µ–Ω–∏–µ NaN.
    #    Matplotlib –Ω–µ –±—É–¥–µ—Ç —Å–æ–µ–¥–∏–Ω—è—Ç—å –ª–∏–Ω–∏—è–º–∏ —Ç–æ—á–∫–∏, –º–µ–∂–¥—É –∫–æ—Ç–æ—Ä—ã–º–∏ –µ—Å—Ç—å NaN.
    df_backtest.loc[df_backtest['volume'].fillna(0) == 0, 'plot_close'] = np.nan
    # --- üëÜüëÜüëÜ –ö–û–ù–ï–¶ –ù–û–í–û–ì–û –†–ï–®–ï–ù–ò–Ø üëÜüëÜüëÜ ---

    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 12), sharex=True, gridspec_kw={'height_ratios': [3, 1]})
    
    # –í–µ—Ä—Ö–Ω–∏–π –≥—Ä–∞—Ñ–∏–∫: –¶–µ–Ω–∞ –∏ —Å–∏–≥–Ω–∞–ª—ã
    ax1.plot(df_backtest['datetime'], df_backtest['plot_close'], label='–¶–µ–Ω–∞ Close', color='cyan', alpha=0.9, linewidth=1.2)
    
    # –î–ª—è —Å–∏–≥–Ω–∞–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π df_backtest, —á—Ç–æ–±—ã —Ç–æ—á–∫–∏ —Ä–∏—Å–æ–≤–∞–ª–∏—Å—å –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –≤—ã—Å–æ—Ç–µ
    buy_signals = df_backtest[df_backtest['signal'] == 2]
    sell_signals = df_backtest[df_backtest['signal'] == 0]
    
    ax1.scatter(buy_signals['datetime'], buy_signals['close'], label='Buy', marker='^', color='lime', s=120, zorder=5, edgecolors='black', linewidths=0.5)
    ax1.scatter(sell_signals['datetime'], sell_signals['close'], label='Sell', marker='v', color='red', s=120, zorder=5, edgecolors='black', linewidths=0.5)
    
    ax1.set_title(f"–ë–µ–∫—Ç–µ—Å—Ç –º–æ–¥–µ–ª–∏ '{args.model_name}' –Ω–∞ '{args.ticker}' –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –≥–æ–¥", fontsize=16)
    ax1.set_ylabel("–¶–µ–Ω–∞", fontsize=12)
    ax1.grid(True, linestyle='--', alpha=0.3)
    ax1.legend()
    
    # –ù–∏–∂–Ω–∏–π –≥—Ä–∞—Ñ–∏–∫ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    ax2.plot(df_backtest['datetime'], np.ones(len(df_backtest)), color='gray', linestyle='--')
    ax2.set_title("Portfolio Value (Work in Progress)", fontsize=12)
    ax2.set_xlabel("–î–∞—Ç–∞", fontsize=12)
    ax2.set_ylabel("Value", fontsize=12)
    
    plt.tight_layout()
    
    report_dir = RESULTS_DIR / "reports"
    report_dir.mkdir(exist_ok=True, parents=True)
    output_path = report_dir / f"backtest_{args.model_name}_{args.ticker}.png"
    plt.savefig(output_path)
    print(f"‚úÖ –ì—Ä–∞—Ñ–∏–∫ –±–µ–∫—Ç–µ—Å—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_path}")

    # --- 5. –ü—Ä–æ—Å—Ç–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ---
    trade_days = df_backtest[df_backtest['volume'].fillna(0) > 0]
    n_buys = len(buy_signals)
    n_sells = len(sell_signals)
    buy_and_hold_return = (trade_days['close'].iloc[-1] / trade_days['close'].iloc[0] - 1) * 100
    
    print("\n--- üìä –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ---")
    print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–æ–≤ 'Buy': {n_buys}")
    print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–æ–≤ 'Sell': {n_sells}")
    print(f"–î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å '–ö—É–ø–∏ –∏ –¥–µ—Ä–∂–∏' –∑–∞ –ø–µ—Ä–∏–æ–¥: {buy_and_hold_return:.2f}%")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–ó–∞–ø—É—Å–∫ –±–µ–∫—Ç–µ—Å—Ç–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –æ–¥–Ω–æ–º —Ç–∏–∫–µ—Ä–µ.")
    parser.add_argument("--model_name", type=str, required=True, help="–ò–º—è –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.")
    parser.add_argument("--ticker", type=str, required=True, help="–¢–∏–∫–µ—Ä –∞–∫—Ü–∏–∏ –¥–ª—è –±–µ–∫—Ç–µ—Å—Ç–∞ (–Ω–∞–ø—Ä. SBER).")
    parser.add_argument("--years", type=int, default=1, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–µ—Ç –¥–ª—è –ø–µ—Ä–∏–æ–¥–∞ –±–µ–∫—Ç–µ—Å—Ç–∞.")
    
    args = parser.parse_args()
    main(args)