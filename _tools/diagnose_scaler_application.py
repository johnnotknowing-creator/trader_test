# _tools/diagnose_scaler_application.py
import argparse
import json
import joblib
from pathlib import Path
import pandas as pd
from sklearn.pipeline import Pipeline

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π ---
PROJECT_ROOT = Path(__file__).resolve().parents[1]
RESULTS_DIR = PROJECT_ROOT / "2_results"

def main(args):
    model_name = args.model_name
    print("--- ü©∫ –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Å–∫–µ–π–ª–µ—Ä–∞ ---")
    print(f"–ú–æ–¥–µ–ª—å: {model_name}")

    # --- –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ ---
    try:
        scaler_dir = RESULTS_DIR / "scalers"
        scaler_path = scaler_dir / f"{model_name}_scaler.pkl"
        features_json_path = scaler_dir / f"{model_name}_features.json"

        print(f"–ó–∞–≥—Ä—É–∂–∞—é —Å–∫–µ–π–ª–µ—Ä –∏–∑: {scaler_path}")
        scaler: Pipeline = joblib.load(scaler_path)
        
        print(f"–ó–∞–≥—Ä—É–∂–∞—é —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑: {features_json_path}")
        with open(features_json_path, 'r') as f:
            selected_features = json.load(f)['feature_order']
        
        print(f"‚úÖ –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è: {len(selected_features)}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤: {e}")
        return

    # --- –®–∞–≥ 2: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---
    try:
        source_dir = RESULTS_DIR / "final_for_model" / model_name
        train_path = source_dir / "train_final.csv"
        print(f"–ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ –∏–∑: {train_path}")
        train_df = pd.read_csv(train_path)
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –§–æ—Ä–º–∞: {train_df.shape}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return

    # --- –®–∞–≥ 3: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å–∫–µ–π–ª–µ—Ä–∞ ---
    try:
        print("\\n--- üöÄ –ù–∞—á–∏–Ω–∞—é –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ scaler.transform() –∫ –¥–∞–Ω–Ω—ã–º... ---")
        
        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –Ω–∞ –º–µ—Å—Ç–µ
        for col in selected_features:
            if col not in train_df.columns:
                train_df[col] = 0.0
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é
        scaled_features = scaler.transform(train_df[selected_features])
        
        print("‚úÖ scaler.transform() —É—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω!")
        
        # --- –®–∞–≥ 4: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ ---
        print("\\n--- üìä –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è ---")
        df_scaled = pd.DataFrame(scaled_features, columns=selected_features)
        
        stats = df_scaled.describe().transpose()[['mean', 'std', 'min', 'max']]
        print(stats.to_string())
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –±–ª–∏–∑–∫–∏ –∫ –Ω—É–ª—é, –∞ std - –Ω–µ—Ç
        if stats['mean'].abs().max() < 0.1 and stats['std'].min() > 0.1:
            print("\\nüéâüéâüéâ –í–´–í–û–î: –°–∫–µ–π–ª–µ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ! –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω—ã. üéâüéâüéâ")
        else:
            print("\\n‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –†–µ–∑—É–ª—å—Ç–∞—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –≤—ã–≥–ª—è–¥–∏—Ç –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ. –°—Ä–µ–¥–Ω–∏–µ –Ω–µ —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã –∏–ª–∏ std —Å–ª–∏—à–∫–æ–º –º–∞–ª—ã.")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è scaler.transform(): {e}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –æ–±—É—á–µ–Ω–Ω–æ–≥–æ —Å–∫–µ–π–ª–µ—Ä–∞.")
    parser.add_argument("--model_name", type=str, required=True)
    args = parser.parse_args()
    main(args)