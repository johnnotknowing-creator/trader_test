import argparse
import json
import joblib
from pathlib import Path
import os

os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

import pandas as pd
from tqdm import tqdm
import tensorflow as tf

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π ---
PROJECT_ROOT = Path(__file__).resolve().parents[1]
RESULTS_DIR = PROJECT_ROOT / "2_results"
FEATURES_DIR_PROCESSED = RESULTS_DIR / "features_processed"

def main(args):
    print("--- üëΩ –ó–∞–ø—É—Å–∫ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è '—Å—É–ø–µ—Ä-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤' —Å –ø–æ–º–æ—â—å—é —ç–Ω–∫–æ–¥–µ—Ä–∞ ---")
    print("üî•üî•üî• –í–ù–ò–ú–ê–ù–ò–ï: GPU –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω, –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –±—É–¥–µ—Ç –∏–¥—Ç–∏ –Ω–∞ CPU. üî•üî•üî•")

    autoencoder_dir = RESULTS_DIR / "autoencoders" / args.model_name
    encoder_path = autoencoder_dir / "encoder.keras"
    scaler_path = autoencoder_dir / "scaler.pkl"
    metadata_path = autoencoder_dir / "metadata.json"
    output_dir = RESULTS_DIR / "features_encoded" / args.model_name
    output_dir.mkdir(parents=True, exist_ok=True)

    if not all([encoder_path.exists(), scaler_path.exists(), metadata_path.exists()]):
        print(f"‚ùå –û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω—ã –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –≤ –ø–∞–ø–∫–µ {autoencoder_dir}.")
        return

    print("–ó–∞–≥—Ä—É–∑–∫–∞ —ç–Ω–∫–æ–¥–µ—Ä–∞, —Å–∫–µ–π–ª–µ—Ä–∞ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö...")
    encoder = tf.keras.models.load_model(encoder_path)
    scaler = joblib.load(scaler_path)
    with open(metadata_path, 'r') as f:
        metadata = json.load(f)
    
    # –≠—Ç–æ –Ω–∞—à "–∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π" —Å–ø–∏—Å–æ–∫ –∏–∑ 132 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    source_feature_names = metadata["source_feature_names"]
    encoded_dim = metadata["encoded_dim"]
    encoded_feature_names = [f"AE_{i}" for i in range(encoded_dim)]
    
    print(f"‚úÖ –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –¥–ª—è –º–æ–¥–µ–ª–∏ '{args.model_name}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")

    all_files = list(FEATURES_DIR_PROCESSED.glob("*.csv"))
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(all_files)} —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑ {FEATURES_DIR_PROCESSED}")

    possible_meta_cols = ['datetime', 'ticker', 'open', 'high', 'low', 'close', 'volume', 'label', 'meta_target']

    for file_path in tqdm(all_files, desc="–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"):
        df = pd.read_csv(file_path)
        
        existing_meta_cols = [col for col in possible_meta_cols if col in df.columns]
        df_meta = df[existing_meta_cols].copy()
        
        # --- üëáüëáüëá –§–ò–ù–ê–õ–¨–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï üëáüëáüëá ---
        # 1. –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–º —Å–ø–∏—Å–∫–µ
        existing_features = [col for col in source_feature_names if col in df.columns]
        X = df[existing_features].copy()

        # 2. –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö: –¥–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –∏ –∑–∞–ø–æ–ª–Ω—è–µ–º –∏—Ö –Ω—É–ª—è–º–∏
        missing_features = set(source_feature_names) - set(existing_features)
        if missing_features:
            for feature in missing_features:
                X[feature] = 0
        
        # 3. –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫
        X = X[source_feature_names]
        # --- üëÜüëÜüëÜ –ö–û–ù–ï–¶ –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø üëÜüëÜüëÜ ---
        
        X_scaled = scaler.transform(X.values)
        X_encoded = encoder.predict(X_scaled, verbose=0)
        
        df_encoded_features = pd.DataFrame(X_encoded, columns=encoded_feature_names, index=df.index)
        final_df = pd.concat([df_meta, df_encoded_features], axis=1)
        
        output_path = output_dir / file_path.name
        final_df.to_csv(output_path, index=False)

    print(f"\n‚úÖ –ü—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–µ–Ω. {len(all_files)} —Ñ–∞–π–ª–æ–≤ —Å '—Å—É–ø–µ—Ä-–ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏' —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_dir}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Extract features using a trained autoencoder.")
    parser.add_argument("--model_name", type=str, required=True, 
                        help="The name of the trained autoencoder model to use.")
    args = parser.parse_args()
    main(args)